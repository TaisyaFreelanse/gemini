import logging
from typing import Dict, List, Optional, Callable
from datetime import datetime
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger
from apscheduler.triggers.interval import IntervalTrigger
from apscheduler.job import Job
from apscheduler.jobstores.memory import MemoryJobStore
import asyncio

from app.core.config import settings
import redis
import json

logger = logging.getLogger(__name__)

# Redis –∫–ª—ñ—î–Ω—Ç –¥–ª—è —á–∏—Ç–∞–Ω–Ω—è –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó
_redis_client = None

def _get_redis():
    """–û—Ç—Ä–∏–º–∞—Ç–∏ Redis –∫–ª—ñ—î–Ω—Ç (lazy init)"""
    global _redis_client
    if _redis_client is None:
        _redis_client = redis.from_url(settings.REDIS_URL)
    return _redis_client


def _redis_str(key: str, default: str = "") -> str:
    """–ü—Ä–æ—á–∏—Ç–∞—Ç–∏ —Å—Ç—Ä–æ–∫—É –∑ Redis"""
    try:
        raw = _get_redis().get(key)
        return raw.decode().strip() if raw else default
    except Exception:
        return default


def _redis_int(key: str, default: int) -> int:
    """–ü—Ä–æ—á–∏—Ç–∞—Ç–∏ int –∑ Redis"""
    try:
        raw = _get_redis().get(key)
        return int(raw.decode()) if raw else default
    except Exception:
        return default


REDIS_JOBS_KEY = "scheduler:jobs"


def _save_job_to_redis(job_id: str, job_data: Dict):
    """–ó–±–µ—Ä–µ–≥—Ç–∏ job –≤ Redis –¥–ª—è –≤—ñ–¥–Ω–æ–≤–ª–µ–Ω–Ω—è –ø—ñ—Å–ª—è —Ä–µ—Å—Ç–∞—Ä—Ç—É"""
    try:
        r = _get_redis()
        r.hset(REDIS_JOBS_KEY, job_id, json.dumps(job_data))
        print(f"  ‚úì Job {job_id} saved to Redis", flush=True)
    except Exception as e:
        print(f"  ‚úó Failed to save job {job_id} to Redis: {e}", flush=True)


def _delete_job_from_redis(job_id: str):
    """–í–∏–¥–∞–ª–∏—Ç–∏ job –∑ Redis"""
    try:
        r = _get_redis()
        r.hdel(REDIS_JOBS_KEY, job_id)
        print(f"  ‚úì Job {job_id} deleted from Redis", flush=True)
    except Exception as e:
        print(f"  ‚úó Failed to delete job {job_id} from Redis: {e}", flush=True)


def _get_saved_jobs_from_redis() -> Dict[str, Dict]:
    """–û—Ç—Ä–∏–º–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω—ñ jobs –∑ Redis"""
    try:
        r = _get_redis()
        jobs_raw = r.hgetall(REDIS_JOBS_KEY)
        jobs = {}
        for job_id, job_data in jobs_raw.items():
            job_id_str = job_id.decode() if isinstance(job_id, bytes) else job_id
            job_data_str = job_data.decode() if isinstance(job_data, bytes) else job_data
            jobs[job_id_str] = json.loads(job_data_str)
        return jobs
    except Exception as e:
        print(f"  ‚úó Failed to get jobs from Redis: {e}", flush=True)
        return {}


def _get_current_config() -> Dict:
    """
    –û—Ç—Ä–∏–º–∞—Ç–∏ –∞–∫—Ç—É–∞–ª—å–Ω—É –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—é –∑ Redis —Ç–∞ .env
    –í–∏–∫–ª–∏–∫–∞—î—Ç—å—Å—è –≤ –º–æ–º–µ–Ω—Ç –∑–∞–ø—É—Å–∫—É –∑–∞–¥–∞—á—ñ, —â–æ–± –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ –ø–æ—Ç–æ—á–Ω—ñ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è
    """
    # Gemini
    gemini_key = _redis_str("config:gemini_key") or settings.GEMINI_API_KEY
    prompt_template = _redis_str("config:prompt") or None
    
    # Proxy - —á–∏—Ç–∞—î–º–æ –∑ Redis, fallback –Ω–∞ .env
    proxy_host = _redis_str("config:proxy_host") or settings.PROXY_HOST
    proxy_login = _redis_str("config:proxy_login") or settings.PROXY_LOGIN
    proxy_password = _redis_str("config:proxy_password") or settings.PROXY_PASSWORD
    proxy_http_port = _redis_int("config:proxy_http_port", settings.PROXY_HTTP_PORT)
    proxy_socks_port = _redis_int("config:proxy_socks_port", settings.PROXY_SOCKS_PORT)
    
    # Webhook
    webhook_url = _redis_str("config:webhook_url") or settings.WEBHOOK_URL
    webhook_token = _redis_str("config:webhook_token") or settings.WEBHOOK_TOKEN
    
    config = {
        'gemini_key': gemini_key,
        'prompt': prompt_template,
        'webhook': {
            'url': webhook_url,
            'token': webhook_token
        },
        'proxy': {
            'host': proxy_host,
            'http_port': proxy_http_port,
            'socks_port': proxy_socks_port,
            'login': proxy_login,
            'password': proxy_password
        } if proxy_host else None
    }
    
    logger.info(f"Config loaded: proxy={'enabled' if proxy_host else 'disabled'}, host={proxy_host}")
    
    return config


class SchedulerService:
    """
    –°–µ—Ä–≤—ñ—Å –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü—ñ—ó –ø–∞—Ä—Å–∏–Ω–≥—É —á–µ—Ä–µ–∑ cron
    
    –û—Å–Ω–æ–≤–Ω—ñ –º–æ–∂–ª–∏–≤–æ—Å—Ç—ñ:
    - –ü—ñ–¥—Ç—Ä–∏–º–∫–∞ cron expressions (–Ω–∞–ø—Ä. "0 */6 * * *")
    - –ü–æ–≤–Ω–∏–π –ø–∞—Ä—Å–∏–Ω–≥ –≤—Å—ñ—Ö –¥–æ–º–µ–Ω—ñ–≤
    - –ß–∞—Å—Ç–∫–æ–≤–∏–π –ø–∞—Ä—Å–∏–Ω–≥ (N –¥–æ–º–µ–Ω—ñ–≤ –∑–∞ —Ä–∞–∑)
    - –£–ø—Ä–∞–≤–ª—ñ–Ω–Ω—è –∑–∞–¥–∞—á–∞–º–∏ (–¥–æ–¥–∞–≤–∞–Ω–Ω—è, –≤–∏–¥–∞–ª–µ–Ω–Ω—è, –ø–∞—É–∑–∞)
    - –ú–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ –≤–∏–∫–æ–Ω–∞–Ω–Ω—è –∑–∞–¥–∞—á
    """
    
    def __init__(self):
        """–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è scheduler"""
        # –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è jobstore
        jobstores = {
            'default': MemoryJobStore()
        }
        
        # –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è executor
        job_defaults = {
            'coalesce': True,  # –û–±'—î–¥–Ω–∞—Ç–∏ –ø—Ä–æ–ø—É—â–µ–Ω—ñ –∑–∞–ø—É—Å–∫–∏
            'max_instances': 1,  # –ù–µ –∑–∞–ø—É—Å–∫–∞—Ç–∏ –ø–∞—Ä–∞–ª–µ–ª—å–Ω—ñ –∫–æ–ø—ñ—ó –æ–¥–Ω—ñ—î—ó –∑–∞–¥–∞—á—ñ
            'misfire_grace_time': 300  # 5 —Ö–≤–∏–ª–∏–Ω grace period
        }
        
        self.scheduler = AsyncIOScheduler(
            jobstores=jobstores,
            job_defaults=job_defaults,
            timezone='UTC'
        )
        
        self._is_running = False
        logger.info("SchedulerService —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–æ")
    
    def start(self):
        """–ó–∞–ø—É—Å—Ç–∏—Ç–∏ scheduler"""
        print(f"  SchedulerService.start() called, _is_running={self._is_running}", flush=True)
        if not self._is_running:
            try:
                # –î–ª—è AsyncIOScheduler –ø–æ—Ç—Ä—ñ–±–µ–Ω event loop
                import asyncio
                try:
                    loop = asyncio.get_running_loop()
                    print(f"  Event loop found: {loop}", flush=True)
                except RuntimeError:
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    print(f"  Created new event loop: {loop}", flush=True)
                
                self.scheduler.start()
                self._is_running = True
                print(f"  ‚úì Scheduler started successfully, state: {self.scheduler.state}", flush=True)
                logger.info("‚úì Scheduler –∑–∞–ø—É—â–µ–Ω–æ")
                
                # –í—ñ–¥–Ω–æ–≤–ª—é—î–º–æ –∑–±–µ—Ä–µ–∂–µ–Ω—ñ jobs –∑ Redis
                self._restore_jobs_from_redis()
                
            except Exception as e:
                print(f"  ‚úó Scheduler start error: {e}", flush=True)
                import traceback
                traceback.print_exc()
        else:
            logger.warning("Scheduler –≤–∂–µ –∑–∞–ø—É—â–µ–Ω–∏–π")
    
    def _restore_jobs_from_redis(self):
        """–í—ñ–¥–Ω–æ–≤–∏—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω—ñ jobs –∑ Redis –ø—ñ—Å–ª—è —Ä–µ—Å—Ç–∞—Ä—Ç—É"""
        print("  Restoring jobs from Redis...", flush=True)
        saved_jobs = _get_saved_jobs_from_redis()
        
        if not saved_jobs:
            print("  No saved jobs found in Redis", flush=True)
            return
        
        print(f"  Found {len(saved_jobs)} saved jobs in Redis", flush=True)
        
        for job_id, job_data in saved_jobs.items():
            try:
                job_type = job_data.get('type')
                cron_expression = job_data.get('cron_expression')
                domains = job_data.get('domains', [])
                
                print(f"  Restoring job {job_id}: type={job_type}, cron={cron_expression}, domains={len(domains)}", flush=True)
                
                if job_type == 'full_scraping' and domains:
                    # –í—ñ–¥–Ω–æ–≤–ª—é—î–º–æ full_scraping job
                    self.schedule_full_scraping(
                        cron_expression=cron_expression,
                        domains=domains,
                        config=None,
                        save_to_redis=False  # –ù–µ –∑–±–µ—Ä—ñ–≥–∞—Ç–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ
                    )
                    print(f"  ‚úì Job {job_id} restored successfully", flush=True)
                elif job_type == 'partial_scraping' and domains:
                    batch_size = job_data.get('batch_size', 500)
                    self.schedule_partial_scraping(
                        cron_expression=cron_expression,
                        all_domains=domains,
                        batch_size=batch_size,
                        config=None,
                        save_to_redis=False
                    )
                    print(f"  ‚úì Job {job_id} restored successfully", flush=True)
                else:
                    print(f"  ‚ö† Unknown job type or empty domains: {job_type}", flush=True)
                    
            except Exception as e:
                print(f"  ‚úó Failed to restore job {job_id}: {e}", flush=True)
                import traceback
                traceback.print_exc()
    
    def shutdown(self, wait: bool = True):
        """
        –ó—É–ø–∏–Ω–∏—Ç–∏ scheduler
        
        Args:
            wait: –ß–µ–∫–∞—Ç–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è –ø–æ—Ç–æ—á–Ω–∏—Ö –∑–∞–¥–∞—á
        """
        if self._is_running:
            self.scheduler.shutdown(wait=wait)
            self._is_running = False
            logger.info("‚úì Scheduler –∑—É–ø–∏–Ω–µ–Ω–æ")
        else:
            logger.warning("Scheduler –≤–∂–µ –∑—É–ø–∏–Ω–µ–Ω–∏–π")
    
    def is_running(self) -> bool:
        """–ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —á–∏ –ø—Ä–∞—Ü—é—î scheduler"""
        return self._is_running
    
    # ========== –î–æ–¥–∞–≤–∞–Ω–Ω—è –∑–∞–¥–∞—á ==========
    
    def add_cron_job(
        self,
        job_id: str,
        func: Callable,
        cron_expression: str,
        args: tuple = (),
        kwargs: dict = None,
        description: str = ""
    ) -> Optional[Job]:
        """
        –î–æ–¥–∞—Ç–∏ –∑–∞–¥–∞—á—É –∑ cron expression
        
        Args:
            job_id: –£–Ω—ñ–∫–∞–ª—å–Ω–∏–π ID –∑–∞–¥–∞—á—ñ
            func: –§—É–Ω–∫—Ü—ñ—è –¥–ª—è –≤–∏–∫–æ–Ω–∞–Ω–Ω—è
            cron_expression: Cron expression (–Ω–∞–ø—Ä. "0 */6 * * *")
            args: –ü–æ–∑–∏—Ü—ñ–π–Ω—ñ –∞—Ä–≥—É–º–µ–Ω—Ç–∏ –¥–ª—è —Ñ—É–Ω–∫—Ü—ñ—ó
            kwargs: –Ü–º–µ–Ω–æ–≤–∞–Ω—ñ –∞—Ä–≥—É–º–µ–Ω—Ç–∏ –¥–ª—è —Ñ—É–Ω–∫—Ü—ñ—ó
            description: –û–ø–∏—Å –∑–∞–¥–∞—á—ñ
        
        Returns:
            Job instance –∞–±–æ None —è–∫—â–æ –ø–æ–º–∏–ª–∫–∞
        
        Examples:
            - "0 */6 * * *" - –∫–æ–∂–Ω—ñ 6 –≥–æ–¥–∏–Ω
            - "0 0 * * *" - —â–æ–¥–Ω—è –æ 00:00
            - "*/30 * * * *" - –∫–æ–∂–Ω—ñ 30 —Ö–≤–∏–ª–∏–Ω
        """
        try:
            # –ü–∞—Ä—Å–∏–º–æ cron expression (5 –ø–æ–ª—ñ–≤: minute hour day month day_of_week)
            raw = (cron_expression or "").strip()
            parts = raw.split()
            # –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è: —è–∫—â–æ 4 –ø–æ–ª—è ‚Äî –¥–æ–¥–∞—Ç–∏ day_of_week=*
            if len(parts) == 4:
                parts.append('*')
            if len(parts) == 1:
                if parts[0] == '*' or parts[0].lower() == 'every_minute':
                    parts = ['*', '*', '*', '*', '*']  # –∫–æ–∂–Ω—É —Ö–≤–∏–ª–∏–Ω—É
                else:
                    parts = [parts[0], '*', '*', '*', '*']  # —Ö–≤ N —â–æ–≥–æ–¥–∏–Ω–∏
            if len(parts) != 5:
                raise ValueError(
                    "Cron –º–∞—î 5 –ø–æ–ª—ñ–≤: minute hour day month day_of_week. "
                    "–ü—Ä–∏–∫–ª–∞–¥: * * * * * (–∫–æ–∂–Ω—É —Ö–≤), */5 * * * * (–∫–æ–∂–Ω—ñ 5 —Ö–≤), 0 */6 * * * (–∫–æ–∂–Ω—ñ 6 –≥–æ–¥)"
                )
            expr = ' '.join(parts)
            trigger = CronTrigger.from_crontab(expr, timezone='UTC')
            
            # –û–±–≥–æ—Ä—Ç–∫–∞ –¥–ª—è –ª–æ–≥—É–≤–∞–Ω–Ω—è –≤–∏–∫–ª–∏–∫—É
            def job_wrapper(*a, **kw):
                logger.info(f"üîî CRON TRIGGER FIRED: {job_id}")
                try:
                    return func(*a, **kw)
                except Exception as e:
                    logger.error(f"‚úó Job {job_id} failed: {e}")
                    raise
            
            job = self.scheduler.add_job(
                func=job_wrapper,
                trigger=trigger,
                id=job_id,
                args=args,
                kwargs=kwargs or {},
                replace_existing=True
            )
            
            logger.info(
                f"‚úì –î–æ–¥–∞–Ω–æ cron –∑–∞–¥–∞—á—É '{job_id}': {cron_expression} "
                f"(–Ω–∞—Å—Ç—É–ø–Ω–∏–π –∑–∞–ø—É—Å–∫: {job.next_run_time})"
            )
            logger.info(f"  Scheduler running: {self._is_running}, Jobs count: {len(self.scheduler.get_jobs())}")
            
            return job
            
        except Exception as e:
            logger.error(f"‚úó –ü–æ–º–∏–ª–∫–∞ –¥–æ–¥–∞–≤–∞–Ω–Ω—è cron –∑–∞–¥–∞—á—ñ '{job_id}': {e}")
            return None
    
    def add_interval_job(
        self,
        job_id: str,
        func: Callable,
        interval_minutes: int,
        args: tuple = (),
        kwargs: dict = None,
        description: str = ""
    ) -> Optional[Job]:
        """
        –î–æ–¥–∞—Ç–∏ –∑–∞–¥–∞—á—É –∑ —ñ–Ω—Ç–µ—Ä–≤–∞–ª–æ–º
        
        Args:
            job_id: –£–Ω—ñ–∫–∞–ª—å–Ω–∏–π ID –∑–∞–¥–∞—á—ñ
            func: –§—É–Ω–∫—Ü—ñ—è –¥–ª—è –≤–∏–∫–æ–Ω–∞–Ω–Ω—è
            interval_minutes: –Ü–Ω—Ç–µ—Ä–≤–∞–ª –≤ —Ö–≤–∏–ª–∏–Ω–∞—Ö
            args: –ü–æ–∑–∏—Ü—ñ–π–Ω—ñ –∞—Ä–≥—É–º–µ–Ω—Ç–∏
            kwargs: –Ü–º–µ–Ω–æ–≤–∞–Ω—ñ –∞—Ä–≥—É–º–µ–Ω—Ç–∏
            description: –û–ø–∏—Å –∑–∞–¥–∞—á—ñ
        
        Returns:
            Job instance –∞–±–æ None
        """
        try:
            trigger = IntervalTrigger(minutes=interval_minutes, timezone='UTC')
            
            job = self.scheduler.add_job(
                func=func,
                trigger=trigger,
                id=job_id,
                args=args,
                kwargs=kwargs or {},
                replace_existing=True
            )
            
            logger.info(
                f"‚úì –î–æ–¥–∞–Ω–æ interval –∑–∞–¥–∞—á—É '{job_id}': –∫–æ–∂–Ω—ñ {interval_minutes} —Ö–≤ "
                f"(–Ω–∞—Å—Ç—É–ø–Ω–∏–π –∑–∞–ø—É—Å–∫: {job.next_run_time})"
            )
            
            return job
            
        except Exception as e:
            logger.error(f"‚úó –ü–æ–º–∏–ª–∫–∞ –¥–æ–¥–∞–≤–∞–Ω–Ω—è interval –∑–∞–¥–∞—á—ñ '{job_id}': {e}")
            return None
    
    # ========== –£–ø—Ä–∞–≤–ª—ñ–Ω–Ω—è –∑–∞–¥–∞—á–∞–º–∏ ==========
    
    def remove_job(self, job_id: str) -> bool:
        """
        –í–∏–¥–∞–ª–∏—Ç–∏ –∑–∞–¥–∞—á—É
        
        Args:
            job_id: ID –∑–∞–¥–∞—á—ñ
        
        Returns:
            True —è–∫—â–æ —É—Å–ø—ñ—à–Ω–æ –≤–∏–¥–∞–ª–µ–Ω–æ
        """
        try:
            self.scheduler.remove_job(job_id)
            # –í–∏–¥–∞–ª—è—î–º–æ –∑ Redis —Ç–∞–∫–æ–∂
            _delete_job_from_redis(job_id)
            logger.info(f"‚úì –ó–∞–¥–∞—á—É '{job_id}' –≤–∏–¥–∞–ª–µ–Ω–æ")
            return True
        except Exception as e:
            logger.error(f"‚úó –ü–æ–º–∏–ª–∫–∞ –≤–∏–¥–∞–ª–µ–Ω–Ω—è –∑–∞–¥–∞—á—ñ '{job_id}': {e}")
            return False
    
    def pause_job(self, job_id: str) -> bool:
        """–ü—Ä–∏–∑—É–ø–∏–Ω–∏—Ç–∏ –∑–∞–¥–∞—á—É"""
        try:
            self.scheduler.pause_job(job_id)
            logger.info(f"‚úì –ó–∞–¥–∞—á—É '{job_id}' –ø—Ä–∏–∑—É–ø–∏–Ω–µ–Ω–æ")
            return True
        except Exception as e:
            logger.error(f"‚úó –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏–∑—É–ø–∏–Ω–µ–Ω–Ω—è –∑–∞–¥–∞—á—ñ '{job_id}': {e}")
            return False
    
    def resume_job(self, job_id: str) -> bool:
        """–í—ñ–¥–Ω–æ–≤–∏—Ç–∏ –∑–∞–¥–∞—á—É"""
        try:
            self.scheduler.resume_job(job_id)
            logger.info(f"‚úì –ó–∞–¥–∞—á—É '{job_id}' –≤—ñ–¥–Ω–æ–≤–ª–µ–Ω–æ")
            return True
        except Exception as e:
            logger.error(f"‚úó –ü–æ–º–∏–ª–∫–∞ –≤—ñ–¥–Ω–æ–≤–ª–µ–Ω–Ω—è –∑–∞–¥–∞—á—ñ '{job_id}': {e}")
            return False
    
    def get_job(self, job_id: str) -> Optional[Job]:
        """–û—Ç—Ä–∏–º–∞—Ç–∏ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –∑–∞–¥–∞—á—É"""
        return self.scheduler.get_job(job_id)
    
    def get_all_jobs(self) -> List[Dict]:
        """
        –û—Ç—Ä–∏–º–∞—Ç–∏ —Å–ø–∏—Å–æ–∫ –≤—Å—ñ—Ö –∑–∞–¥–∞—á
        
        Returns:
            List[Dict] –∑ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—î—é –ø—Ä–æ –∑–∞–¥–∞—á—ñ
        """
        jobs = self.scheduler.get_jobs()
        
        result = []
        for job in jobs:
            result.append({
                'id': job.id,
                'name': job.name,
                'next_run_time': job.next_run_time.isoformat() if job.next_run_time else None,
                'trigger': str(job.trigger),
                'func': f"{job.func.__module__}.{job.func.__name__}",
                'pending': job.pending
            })
        
        return result
    
    # ========== –°–ø–µ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ –∑–∞–¥–∞—á—ñ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥—É ==========
    
    def schedule_full_scraping(
        self,
        cron_expression: str,
        domains: List[str],
        config: Optional[Dict] = None,
        save_to_redis: bool = True
    ) -> Optional[Job]:
        """
        –ó–∞–ø–ª–∞–Ω—É–≤–∞—Ç–∏ –ø–æ–≤–Ω–∏–π –ø–∞—Ä—Å–∏–Ω–≥ –≤—Å—ñ—Ö –¥–æ–º–µ–Ω—ñ–≤
        
        Args:
            cron_expression: Cron –≤–∏—Ä–∞–∑ (–Ω–∞–ø—Ä. "0 0 * * *")
            domains: –°–ø–∏—Å–æ–∫ –¥–æ–º–µ–Ω—ñ–≤ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥—É
            config: –î–æ–¥–∞—Ç–∫–æ–≤–∞ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è (—ñ–≥–Ω–æ—Ä—É—î—Ç—å—Å—è, —á–∏—Ç–∞—î—Ç—å—Å—è –∑ Redis/.env)
            save_to_redis: –ó–±–µ—Ä—ñ–≥–∞—Ç–∏ –≤ Redis –¥–ª—è –≤—ñ–¥–Ω–æ–≤–ª–µ–Ω–Ω—è –ø—ñ—Å–ª—è —Ä–µ—Å—Ç–∞—Ä—Ç—É
        
        Returns:
            Job instance –∞–±–æ None
        """
        from app.tasks.scraping_tasks import start_batch_scraping
        from app.db.session import SessionLocal
        from app.db import crud
        
        job_id = "full_scraping"
        
        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –≤ Redis –¥–ª—è –≤—ñ–¥–Ω–æ–≤–ª–µ–Ω–Ω—è –ø—ñ—Å–ª—è —Ä–µ—Å—Ç–∞—Ä—Ç—É
        if save_to_redis:
            _save_job_to_redis(job_id, {
                'type': 'full_scraping',
                'cron_expression': cron_expression,
                'domains': domains
            })
        
        def run_full_scraping():
            """Wrapper –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –≤–∏–∫–ª–∏–∫—É Celery task"""
            print(f"üöÄ CRON JOB TRIGGERED: run_full_scraping at {datetime.now()}", flush=True)
            logger.info("üöÄ CRON JOB TRIGGERED: run_full_scraping")
            
            try:
                # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ —î –∞–∫—Ç–∏–≤–Ω–∞ —Å–µ—Å—ñ—è –ø–∞—Ä—Å–∏–Ω–≥—É
                r = _get_redis()
                active_session = r.get("parsing:active_session")
                if active_session:
                    active_session_id = active_session.decode() if isinstance(active_session, bytes) else active_session
                    print(f"‚è≠ –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ: –∞–∫—Ç–∏–≤–Ω–∞ —Å–µ—Å—ñ—è {active_session_id} —â–µ –Ω–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∞", flush=True)
                    logger.warning(f"–ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ –∑–∞–ø—É—Å–∫: –∞–∫—Ç–∏–≤–Ω–∞ —Å–µ—Å—ñ—è {active_session_id} —â–µ –Ω–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
                    return
                
                # –ß–∏—Ç–∞—î–º–æ –∞–∫—Ç—É–∞–ª—å–Ω–∏–π –∫–æ–Ω—Ñ—ñ–≥ –≤ –º–æ–º–µ–Ω—Ç –∑–∞–ø—É—Å–∫—É (–Ω–µ –ø—Ä–∏ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—ñ job)
                runtime_config = _get_current_config()
                logger.info(f"Config loaded, proxy: {runtime_config.get('proxy', {}).get('host', 'none')}")
                
                # –°—Ç–≤–æ—Ä—é—î–º–æ —Å–µ—Å—ñ—é –≤ –ë–î
                db = SessionLocal()
                try:
                    db_session = crud.create_scraping_session(db, total_domains=len(domains))
                    session_id = db_session.id
                    
                    # –ü–æ–∑–Ω–∞—á–∞—î–º–æ –∞–∫—Ç–∏–≤–Ω—É —Å–µ—Å—ñ—é –≤ Redis (TTL 2 –≥–æ–¥–∏–Ω–∏)
                    r.setex("parsing:active_session", 7200, str(session_id))
                    
                    # –í—Å—Ç–∞–Ω–æ–≤–ª—é—î–º–æ —Å—Ç–∞—Ç—É—Å –¥–ª—è Dashboard
                    r.set("scraping:status", "running")
                    r.set("scraping:session_id", str(session_id))
                    
                    print(f"‚úì –ó–∞–ø—É—Å–∫ –ø–æ–≤–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥—É: {len(domains)} –¥–æ–º–µ–Ω—ñ–≤, —Å–µ—Å—ñ—è {session_id}", flush=True)
                    logger.info(f"‚úì –ó–∞–ø—É—Å–∫ –ø–æ–≤–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥—É: {len(domains)} –¥–æ–º–µ–Ω—ñ–≤, —Å–µ—Å—ñ—è {session_id}")
                    
                    result = start_batch_scraping.delay(domains, session_id, runtime_config)
                    print(f"‚úì Celery task –∑–∞–ø—É—â–µ–Ω–æ: {result.id}", flush=True)
                    logger.info(f"‚úì Celery task –∑–∞–ø—É—â–µ–Ω–æ: {result.id}")
                except Exception as e:
                    print(f"‚úó –ü–æ–º–∏–ª–∫–∞ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è —Å–µ—Å—ñ—ó –ø–∞—Ä—Å–∏–Ω–≥—É: {e}", flush=True)
                    logger.error(f"‚úó –ü–æ–º–∏–ª–∫–∞ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è —Å–µ—Å—ñ—ó –ø–∞—Ä—Å–∏–Ω–≥—É: {e}")
                    import traceback
                    logger.error(traceback.format_exc())
                finally:
                    db.close()
            except Exception as e:
                print(f"‚úó CRON JOB ERROR: {e}", flush=True)
                logger.error(f"‚úó CRON JOB ERROR: {e}")
                import traceback
                logger.error(traceback.format_exc())
        
        return self.add_cron_job(
            job_id=job_id,
            func=run_full_scraping,
            cron_expression=cron_expression,
            description=f"–ü–æ–≤–Ω–∏–π –ø–∞—Ä—Å–∏–Ω–≥ {len(domains)} –¥–æ–º–µ–Ω—ñ–≤"
        )
    
    def schedule_partial_scraping(
        self,
        cron_expression: str,
        all_domains: List[str],
        batch_size: int = 500,
        config: Optional[Dict] = None,
        save_to_redis: bool = True
    ) -> Optional[Job]:
        """
        –ó–∞–ø–ª–∞–Ω—É–≤–∞—Ç–∏ —á–∞—Å—Ç–∫–æ–≤–∏–π –ø–∞—Ä—Å–∏–Ω–≥ (N –¥–æ–º–µ–Ω—ñ–≤ –∑–∞ —Ä–∞–∑)
        
        Args:
            cron_expression: Cron –≤–∏—Ä–∞–∑
            all_domains: –ü–æ–≤–Ω–∏–π —Å–ø–∏—Å–æ–∫ –¥–æ–º–µ–Ω—ñ–≤
            batch_size: –ö—ñ–ª—å–∫—ñ—Å—Ç—å –¥–æ–º–µ–Ω—ñ–≤ –≤ –æ–¥–Ω—ñ–π –ø–∞—á—Ü—ñ
            config: –î–æ–¥–∞—Ç–∫–æ–≤–∞ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è (—ñ–≥–Ω–æ—Ä—É—î—Ç—å—Å—è, —á–∏—Ç–∞—î—Ç—å—Å—è –∑ Redis/.env)
            save_to_redis: –ó–±–µ—Ä—ñ–≥–∞—Ç–∏ –≤ Redis –¥–ª—è –≤—ñ–¥–Ω–æ–≤–ª–µ–Ω–Ω—è –ø—ñ—Å–ª—è —Ä–µ—Å—Ç–∞—Ä—Ç—É
        
        Returns:
            Job instance –∞–±–æ None
        """
        from app.tasks.scraping_tasks import start_batch_scraping
        from app.db.session import SessionLocal
        from app.db import crud
        import random
        
        job_id = "partial_scraping"
        
        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –≤ Redis –¥–ª—è –≤—ñ–¥–Ω–æ–≤–ª–µ–Ω–Ω—è –ø—ñ—Å–ª—è —Ä–µ—Å—Ç–∞—Ä—Ç—É
        if save_to_redis:
            _save_job_to_redis(job_id, {
                'type': 'partial_scraping',
                'cron_expression': cron_expression,
                'domains': all_domains,
                'batch_size': batch_size
            })
        
        def run_partial_scraping():
            """Wrapper –¥–ª—è —á–∞—Å—Ç–∫–æ–≤–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥—É"""
            # –ß–∏—Ç–∞—î–º–æ –∞–∫—Ç—É–∞–ª—å–Ω–∏–π –∫–æ–Ω—Ñ—ñ–≥ –≤ –º–æ–º–µ–Ω—Ç –∑–∞–ø—É—Å–∫—É
            runtime_config = _get_current_config()
            
            # –í–∏–±–∏—Ä–∞—î–º–æ –≤–∏–ø–∞–¥–∫–æ–≤—ñ –¥–æ–º–µ–Ω–∏ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥—É
            domains_batch = random.sample(
                all_domains,
                min(batch_size, len(all_domains))
            )
            
            # –°—Ç–≤–æ—Ä—é—î–º–æ —Å–µ—Å—ñ—é –≤ –ë–î
            db = SessionLocal()
            try:
                r = _get_redis()
                
                # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ —î –∞–∫—Ç–∏–≤–Ω–∞ —Å–µ—Å—ñ—è –ø–∞—Ä—Å–∏–Ω–≥—É
                active_session = r.get("parsing:active_session")
                if active_session:
                    active_session_id = active_session.decode() if isinstance(active_session, bytes) else active_session
                    logger.warning(f"–ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ –∑–∞–ø—É—Å–∫: –∞–∫—Ç–∏–≤–Ω–∞ —Å–µ—Å—ñ—è {active_session_id} —â–µ –Ω–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
                    return
                
                db_session = crud.create_scraping_session(db, total_domains=len(domains_batch))
                session_id = db_session.id
                
                # –ü–æ–∑–Ω–∞—á–∞—î–º–æ –∞–∫—Ç–∏–≤–Ω—É —Å–µ—Å—ñ—é –≤ Redis
                r.setex("parsing:active_session", 7200, str(session_id))
                r.set("scraping:status", "running")
                r.set("scraping:session_id", str(session_id))
                
                logger.info(
                    f"–ó–∞–ø—É—Å–∫ —á–∞—Å—Ç–∫–æ–≤–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥—É: {len(domains_batch)}/{len(all_domains)} –¥–æ–º–µ–Ω—ñ–≤, "
                    f"—Å–µ—Å—ñ—è {session_id}"
                )
                
                result = start_batch_scraping.delay(domains_batch, session_id, runtime_config)
                logger.info(f"Celery task –∑–∞–ø—É—â–µ–Ω–æ: {result.id}")
            except Exception as e:
                logger.error(f"–ü–æ–º–∏–ª–∫–∞ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è —Å–µ—Å—ñ—ó –ø–∞—Ä—Å–∏–Ω–≥—É: {e}")
            finally:
                db.close()
        
        return self.add_cron_job(
            job_id=job_id,
            func=run_partial_scraping,
            cron_expression=cron_expression,
            description=f"–ß–∞—Å—Ç–∫–æ–≤–∏–π –ø–∞—Ä—Å–∏–Ω–≥ {batch_size}/{len(all_domains)} –¥–æ–º–µ–Ω—ñ–≤"
        )
    
    def schedule_cleanup_old_sessions(
        self,
        interval_hours: int = 24
    ) -> Optional[Job]:
        """
        –ó–∞–ø–ª–∞–Ω—É–≤–∞—Ç–∏ –æ—á–∏—â–µ–Ω–Ω—è —Å—Ç–∞—Ä–∏—Ö —Å–µ—Å—ñ–π –∑ Redis
        
        Args:
            interval_hours: –Ü–Ω—Ç–µ—Ä–≤–∞–ª –≤ –≥–æ–¥–∏–Ω–∞—Ö
        
        Returns:
            Job instance –∞–±–æ None
        """
        from app.tasks.scraping_tasks import cleanup_old_sessions
        
        def run_cleanup():
            """Wrapper –¥–ª—è –æ—á–∏—â–µ–Ω–Ω—è"""
            logger.info("–ó–∞–ø—É—Å–∫ –æ—á–∏—â–µ–Ω–Ω—è —Å—Ç–∞—Ä–∏—Ö —Å–µ—Å—ñ–π...")
            cleanup_old_sessions.delay()
        
        return self.add_interval_job(
            job_id="cleanup_sessions",
            func=run_cleanup,
            interval_minutes=interval_hours * 60,
            description="–û—á–∏—â–µ–Ω–Ω—è —Å—Ç–∞—Ä–∏—Ö —Å–µ—Å—ñ–π –∑ Redis"
        )


# –ì–ª–æ–±–∞–ª—å–Ω–∏–π instance scheduler
_scheduler_instance: Optional[SchedulerService] = None


def get_scheduler() -> SchedulerService:
    """
    –û—Ç—Ä–∏–º–∞—Ç–∏ –≥–ª–æ–±–∞–ª—å–Ω–∏–π instance scheduler
    
    Returns:
        SchedulerService instance
    """
    global _scheduler_instance
    
    if _scheduler_instance is None:
        _scheduler_instance = SchedulerService()
    
    return _scheduler_instance


def init_default_jobs(domains: List[str], config: Optional[Dict] = None):
    """
    –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É–≤–∞—Ç–∏ –¥–µ—Ñ–æ–ª—Ç–Ω—ñ –∑–∞–¥–∞—á—ñ
    
    Args:
        domains: –°–ø–∏—Å–æ–∫ –¥–æ–º–µ–Ω—ñ–≤ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥—É
        config: –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è –ø–∞—Ä—Å–∏–Ω–≥—É
    """
    scheduler = get_scheduler()
    
    # –ó–∞–ø—É—Å–∫–∞—î–º–æ scheduler —è–∫—â–æ –Ω–µ –∑–∞–ø—É—â–µ–Ω–∏–π
    if not scheduler.is_running():
        scheduler.start()
    
    logger.info("–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –¥–µ—Ñ–æ–ª—Ç–Ω–∏—Ö cron –∑–∞–¥–∞—á...")
    
    # 1. –ü–æ–≤–Ω–∏–π –ø–∞—Ä—Å–∏–Ω–≥ –∫–æ–∂–Ω—ñ 6 –≥–æ–¥–∏–Ω
    scheduler.schedule_full_scraping(
        cron_expression="0 */6 * * *",
        domains=domains,
        config=config
    )
    
    # 2. –ß–∞—Å—Ç–∫–æ–≤–∏–π –ø–∞—Ä—Å–∏–Ω–≥ –∫–æ–∂–Ω—ñ 2 –≥–æ–¥–∏–Ω–∏ (500 –¥–æ–º–µ–Ω—ñ–≤)
    scheduler.schedule_partial_scraping(
        cron_expression="0 */2 * * *",
        all_domains=domains,
        batch_size=500,
        config=config
    )
    
    # 3. –û—á–∏—â–µ–Ω–Ω—è —Å—Ç–∞—Ä–∏—Ö —Å–µ—Å—ñ–π —Ä–∞–∑ –Ω–∞ –¥–æ–±—É
    scheduler.schedule_cleanup_old_sessions(interval_hours=24)
    
    logger.info("‚úì –î–µ—Ñ–æ–ª—Ç–Ω—ñ cron –∑–∞–¥–∞—á—ñ –¥–æ–¥–∞–Ω–æ")
    
    # –í–∏–≤–æ–¥–∏–º–æ —Å–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á
    jobs = scheduler.get_all_jobs()
    logger.info(f"–ê–∫—Ç–∏–≤–Ω–∏—Ö –∑–∞–¥–∞—á: {len(jobs)}")
    for job in jobs:
        logger.info(f"  - {job['id']}: –Ω–∞—Å—Ç—É–ø–Ω–∏–π –∑–∞–ø—É—Å–∫ {job['next_run_time']}")
